{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gwan98/Project/blob/main/YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYMuclM_N97m",
        "outputId": "41ab665f-025c-4840-8139-6845a32fe173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!cd yolov5;pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/gdrive/MyDrive/data"
      ],
      "metadata": {
        "id": "sRymVdTCOCPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpaTWvsZODol",
        "outputId": "faa65e5b-ef84-4fd7-fa3d-bb735e2c277a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjbqcsOkhEU3",
        "outputId": "413096fa-aecf-4137-ad84-9bed247e26b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvR3Ay0KhUiX",
        "outputId": "a58923ee-dcd5-4638-87c7-5c548b3a3b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import IntVar\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "def split_dataset(input_json, output_dir, val_ratio, test_ratio, random_seed):\n",
        "    random.seed(random_seed)\n",
        "\n",
        "    with open(input_json) as json_reader:\n",
        "        dataset = json.load(json_reader)\n",
        "\n",
        "    images = dataset['images']\n",
        "    annotations = dataset['annotations']\n",
        "    categories = dataset['categories']\n",
        "\n",
        "    # file_nameÏóê prefix ÎîîÎ†âÌÜ†Î¶¨ÍπåÏßÄ Ìè¨Ìï® (CocoDataset ÌÅ¥ÎûòÏä§Î•º ÏÇ¨Ïö©ÌïòÎäî Í≤ΩÏö∞)\n",
        "    #for image in images:\n",
        "        #image['file_name'] = '{}/{}'.format(image['file_name'][0], image['file_name'])\n",
        "\n",
        "    image_ids = [x.get('id') for x in images]\n",
        "    image_ids.sort()\n",
        "    random.shuffle(image_ids)\n",
        "\n",
        "    num_val = int(len(image_ids) * val_ratio)\n",
        "    num_test = int(len(image_ids) * test_ratio)\n",
        "    num_train = int(len(image_ids)) - num_val - num_test\n",
        "\n",
        "    image_ids_val, image_ids_train , image_ids_test= set(image_ids[:num_val]), set(image_ids[num_val:num_train]), set(image_ids[num_train:])\n",
        "\n",
        "    train_images = [x for x in images if x.get('id') in image_ids_train]\n",
        "    val_images = [x for x in images if x.get('id') in image_ids_val]\n",
        "    test_images = [x for x in images if x.get('id') in image_ids_test]\n",
        "    train_annotations = [x for x in annotations if x.get('image_id') in image_ids_train]\n",
        "    val_annotations = [x for x in annotations if x.get('image_id') in image_ids_val]\n",
        "    test_annotations = [x for x in annotations if x.get('image_id') in image_ids_test]\n",
        "\n",
        "    train_data = {\n",
        "        'images': train_images,\n",
        "        'annotations': train_annotations,\n",
        "        'categories': categories,\n",
        "    }\n",
        "\n",
        "    val_data = {\n",
        "        'images': val_images,\n",
        "        'annotations': val_annotations,\n",
        "        'categories': categories,\n",
        "    }\n",
        "\n",
        "    test_data = {\n",
        "        'images': test_images,\n",
        "        'annotations': test_annotations,\n",
        "        'categories': categories,\n",
        "    }\n",
        "\n",
        "    output_seed_dir = os.path.join(output_dir, f'seed{random_seed}')\n",
        "    os.makedirs(output_seed_dir, exist_ok=True)\n",
        "    output_train_json = os.path.join(output_seed_dir, 'train.json')\n",
        "    output_val_json = os.path.join(output_seed_dir, 'val.json')\n",
        "    output_test_json = os.path.join(output_seed_dir, 'test.json')\n",
        "    output_train_csv = os.path.join(output_seed_dir, 'train.csv')\n",
        "    output_val_csv = os.path.join(output_seed_dir, 'val.csv')\n",
        "    output_test_csv = os.path.join(output_seed_dir, 'test.csv')\n",
        "\n",
        "    print(f'write {output_train_json}')\n",
        "    with open(output_train_json, 'w') as train_writer:\n",
        "        json.dump(train_data, train_writer)\n",
        "\n",
        "    print(f'write {output_val_json}')\n",
        "    with open(output_val_json, 'w') as val_writer:\n",
        "        json.dump(val_data, val_writer)\n",
        "\n",
        "    print(f'write {output_test_json}')\n",
        "    with open(output_test_json, 'w') as test_writer:\n",
        "        json.dump(test_data, test_writer)"
      ],
      "metadata": {
        "id": "jd7-Ta7GOHkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset(input_json='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/annotation.json',\n",
        "              output_dir='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json',\n",
        "              val_ratio=0.2,\n",
        "              test_ratio=0.1,\n",
        "              random_seed=221112)\n",
        "\n",
        "//Ïã§ÌñâÏôÑÎ£å"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZfrKOtsJZtN",
        "outputId": "b9e68469-eec2-4f90-a3b3-955e5a436437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write /content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/train.json\n",
            "write /content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/val.json\n",
            "write /content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/test.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/alexmihalyk23/COCO2YOLO.git\n",
        "//Ïã§ÌñâÏôÑÎ£å"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWVaySSkKDPS",
        "outputId": "75b036d1-3864-4c42-daa0-bd14f403e490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COCO2YOLO'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 63 (delta 25), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "class COCO2YOLO:\n",
        "  # ÏÜåÏä§ Ïù¥ÎØ∏ÏßÄ ÎîîÎ†âÌÜ†Î¶¨ÏôÄ Json annotation ÌååÏùº, ÌÉÄÍ≤ü Ïù¥ÎØ∏ÏßÄ ÎîîÎ†âÌÜ†Î¶¨, ÌÉÄÍ≤ü annotation ÎîîÎ†âÌÜ†Î¶¨Î•º ÏÉùÏÑ±ÏûêÎ°ú ÏûÖÎ†• Î∞õÏùå. \n",
        "  def __init__(self, src_img_dir, json_file, tgt_img_dir, tgt_anno_dir):\n",
        "    self.json_file = json_file\n",
        "    self.src_img_dir = src_img_dir\n",
        "    self.tgt_img_dir = tgt_img_dir\n",
        "    self.tgt_anno_dir = tgt_anno_dir\n",
        "    # json ÌååÏùºÍ≥º ÌÉÄÍ≤ü ÎîîÎ†âÌÜ†Î¶¨Í∞Ä Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ÌïòÍ≥†, ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÏö∞Îäî ÏóÜÏúºÎ©¥ ÏÉùÏÑ±. \n",
        "    self._check_file_and_dir(json_file, tgt_img_dir, tgt_anno_dir)\n",
        "    # json ÌååÏùºÏùÑ Î©îÎ™®Î¶¨Î°ú Î°úÎî©. \n",
        "    self.labels = json.load(open(json_file, 'r', encoding='utf-8'))\n",
        "    # category idÏôÄ Ïù¥Î¶ÑÏùÑ Îß§ÌïëÌïòÏßÄÎßå, Ïã§Ï†ú class idÎäî Ïù¥Î•º Ï†ÅÏö©ÌïòÏßÄ ÏïäÍ≥† Î≥ÑÎèÑ Ï†ÅÏö©. \n",
        "    self.coco_id_name_map = self._categories()\n",
        "    self.coco_name_list = list(self.coco_id_name_map.values())\n",
        "    print(\"total images\", len(self.labels['images']))\n",
        "    print(\"total categories\", len(self.labels['categories']))\n",
        "    print(\"total labels\", len(self.labels['annotations']))\n",
        "  \n",
        "  # json ÌååÏùºÍ≥º ÌÉÄÍ≤ü ÎîîÎ†âÌÜ†Î¶¨Í∞Ä Ï°¥Ïû¨ÌïòÎäîÏßÄ ÌôïÏù∏ÌïòÍ≥†, ÎîîÎ†âÌÜ†Î¶¨Ïùò Í≤ΩÏö∞Îäî ÏóÜÏúºÎ©¥ ÏÉùÏÑ±. \n",
        "  def _check_file_and_dir(self, file_path, tgt_img_dir, tgt_anno_dir):\n",
        "    if not os.path.exists(file_path):\n",
        "        raise ValueError(\"file not found\")\n",
        "    if not os.path.exists(tgt_img_dir):\n",
        "        os.makedirs(tgt_img_dir)\n",
        "    if not os.path.exists(tgt_anno_dir):\n",
        "        os.makedirs(tgt_anno_dir)\n",
        "\n",
        "  # category idÏôÄ Ïù¥Î¶ÑÏùÑ Îß§ÌïëÌïòÏßÄÎßå, Ï∂îÌõÑÏóê class Î™ÖÎßå ÌôúÏö©. \n",
        "  def _categories(self):\n",
        "    categories = {}\n",
        "    for cls in self.labels['categories']:\n",
        "        categories[cls['id']] = cls['name']\n",
        "    return categories\n",
        "  \n",
        "  # annotationÏóêÏÑú Î™®Îì† imageÏùò ÌååÏùºÎ™Ö(Ï†àÎåÄ Í≤ΩÎ°ú ÏïÑÎãò)Í≥º width, height Ï†ïÎ≥¥ Ï†ÄÏû•. \n",
        "  def _load_images_info(self):\n",
        "    images_info = {}\n",
        "    for image in self.labels['images']:\n",
        "        id = image['id']\n",
        "        file_name = image['file_name']\n",
        "        if file_name.find('\\\\') > -1:\n",
        "            file_name = file_name[file_name.index('\\\\')+1:]\n",
        "        w = image['width']\n",
        "        h = image['height']\n",
        "  \n",
        "        images_info[id] = (file_name, w, h)\n",
        "\n",
        "    return images_info\n",
        "\n",
        "  # ms-cocoÏùò bbox annotationÏùÄ yolo formatÏúºÎ°ú Î≥ÄÌôò. Ï¢åÏÉÅÎã® x, yÏ¢åÌëú, width, height Í∏∞Î∞òÏùÑ Ï†ïÍ∑úÌôîÎêú center x,y ÏôÄ width, heightÎ°ú Î≥ÄÌôò. \n",
        "  def _bbox_2_yolo(self, bbox, img_w, img_h):\n",
        "    # ms-cocoÎäî Ï¢åÏÉÅÎã® x, yÏ¢åÌëú, width, height\n",
        "    x, y, w, h = bbox[0], bbox[1], bbox[2], bbox[3]\n",
        "    # center xÏ¢åÌëúÎäî Ï¢åÏÉÅÎã® xÏ¢åÌëúÏóêÏÑú widthÏùò Ï†àÎ∞òÏùÑ ÎçîÌï®. center yÏ¢åÌëúÎäî Ï¢åÏÉÅÎã® yÏ¢åÌëúÏóêÏÑú heightÏùò Ï†àÎ∞òÏùÑ ÎçîÌï®.  \n",
        "    centerx = bbox[0] + w / 2\n",
        "    centery = bbox[1] + h / 2\n",
        "    # centerx, centery, width, heightÎ•º Ïù¥ÎØ∏ÏßÄÏùò width/heightÎ°ú Ï†ïÍ∑úÌôî. \n",
        "    dw = 1 / img_w\n",
        "    dh = 1 / img_h\n",
        "    centerx *= dw\n",
        "    w *= dw\n",
        "    centery *= dh\n",
        "    h *= dh\n",
        "    return centerx, centery, w, h\n",
        "  \n",
        "  # imageÏôÄ annotation Ï†ïÎ≥¥Î•º Í∏∞Î∞òÏúºÎ°ú imageÎ™ÖÍ≥º yolo annotation Ï†ïÎ≥¥ Í∞ÄÍ≥µ. \n",
        "  # Í∞úÎ≥Ñ imageÎãπ ÌïòÎÇòÏùò annotation Ï†ïÎ≥¥Î•º Í∞ÄÏßÄÎèÑÎ°ù Î≥ÄÌôò. \n",
        "  def _convert_anno(self, images_info):\n",
        "    anno_dict = dict()\n",
        "    for anno in self.labels['annotations']:\n",
        "      bbox = anno['bbox']\n",
        "      image_id = anno['image_id']\n",
        "      category_id = anno['category_id']\n",
        "\n",
        "      image_info = images_info.get(image_id)\n",
        "      image_name = image_info[0]\n",
        "      img_w = image_info[1]\n",
        "      img_h = image_info[2]\n",
        "      yolo_box = self._bbox_2_yolo(bbox, img_w, img_h)\n",
        "\n",
        "      anno_info = (image_name, category_id, yolo_box)\n",
        "      anno_infos = anno_dict.get(image_id)\n",
        "      if not anno_infos:\n",
        "        anno_dict[image_id] = [anno_info]\n",
        "      else:\n",
        "        anno_infos.append(anno_info)\n",
        "        anno_dict[image_id] = anno_infos\n",
        "    return anno_dict\n",
        "\n",
        "  # class Î™ÖÏùÑ ÌååÏùºÎ°ú Ï†ÄÏû•ÌïòÎäî Î°úÏßÅ. ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏùå. \n",
        "  def save_classes(self):\n",
        "    sorted_classes = list(map(lambda x: x['name'], sorted(self.labels['categories'], key=lambda x: x['id'])))\n",
        "    print('coco names', sorted_classes)\n",
        "    with open('coco.names', 'w', encoding='utf-8') as f:\n",
        "      for cls in sorted_classes:\n",
        "          f.write(cls + '\\n')\n",
        "    f.close()\n",
        "  # _convert_anno(images_info)Î°ú ÎßåÎì§Ïñ¥ÏßÑ anno Ï†ïÎ≥¥Î•º Í∞úÎ≥Ñ yolo anno txt ÌååÏùºÎ°ú ÏÉùÏÑ±ÌïòÎäî Î°úÏßÅ. \n",
        "  # coco2yolo()ÏóêÏÑú anno_dict = self._convert_anno(images_info)Î°ú ÎßåÎì§Ïñ¥ÏßÑ anno_dictÎ•º _save_txt()Ïóê ÏûÖÎ†•ÌïòÏó¨ ÌååÏùº ÏÉùÏÑ±\n",
        "  def _save_txt(self, anno_dict):\n",
        "    # Í∞úÎ≥Ñ imageÎ≥ÑÎ°ú ÏÜåÏä§ imageÎäî ÌÉÄÍ≤üÏù¥ÎØ∏ÏßÄ ÎîîÎ†âÌÜ†Î¶¨Î°ú Î≥µÏÇ¨ÌïòÍ≥†, Í∞úÎ≥Ñ annotationÏùÑ ÌÉÄÍ≤ü anno ÎîîÎ†âÌÜ†Î¶¨Î°ú ÏÉùÏÑ±. \n",
        "    for k, v in anno_dict.items():\n",
        "      # ÏÜåÏä§ÏôÄ ÌÉÄÍ≤ü ÌååÏùºÏùò Ï†àÎåÄ Í≤ΩÎ°ú ÏÉùÏÑ±. \n",
        "      src_img_filename = os.path.join(self.src_img_dir, v[0][0])\n",
        "      tgt_anno_filename = os.path.join(self.tgt_anno_dir,v[0][0].split(\".\")[0] + \".txt\")\n",
        "      #print('source image filename:', src_img_filename, 'target anno filename:', tgt_anno_filename)\n",
        "      # Ïù¥ÎØ∏ÏßÄ ÌååÏùºÏùò Í≤ΩÏö∞ ÌÉÄÍ≤ü ÎîîÎ†âÌÜ†Î¶¨Î°ú Îã®Ïàú Î≥µÏÇ¨. \n",
        "      shutil.copy(src_img_filename, self.tgt_img_dir)\n",
        "      # ÌÉÄÍ≤ü annotation Ï∂úÎ†• ÌååÏùºÎ™ÖÏúºÎ°ú classid, bbox Ï¢åÌëúÎ•º object Î≥ÑÎ°ú ÏÉùÏÑ±. \n",
        "      with open(tgt_anno_filename, 'w', encoding='utf-8') as f:\n",
        "        #print(k, v)\n",
        "        # Ïó¨Îü¨Í∞úÏùò object Î≥ÑÎ°ú classidÏôÄ bbox Ï¢åÌëúÎ•º ÏÉùÏÑ±. \n",
        "        for obj in v:\n",
        "          cat_name = self.coco_id_name_map.get(obj[1])\n",
        "          # category_idÎäî class Î™ÖÏóê Îî∞Îùº 0Î∂ÄÌÑ∞ ÏàúÏ∞®Ï†ÅÏúºÎ°ú Î∂ÄÏó¨. \n",
        "          category_id = self.coco_name_list.index(cat_name)\n",
        "          #print('cat_name:', cat_name, 'category_id:', category_id)\n",
        "          box = ['{:.6f}'.format(x) for x in obj[2]]\n",
        "          box = ' '.join(box)\n",
        "          line = str(category_id) + ' ' + box\n",
        "          f.write(line + '\\n')\n",
        "\n",
        "  # ms-cocoÎ•º yolo formatÏúºÎ°ú Î≥ÄÌôò. \n",
        "  def coco2yolo(self):\n",
        "    print(\"loading image info...\")\n",
        "    images_info = self._load_images_info()\n",
        "    print(\"loading done, total images\", len(images_info))\n",
        "\n",
        "    print(\"start converting...\")\n",
        "    anno_dict = self._convert_anno(images_info)\n",
        "    print(\"converting done, total labels\", len(anno_dict))\n",
        "\n",
        "    print(\"saving txt file...\")\n",
        "    self._save_txt(anno_dict)\n",
        "    print(\"saving done\")\n",
        "\n",
        "    //Ïã§ÌñâÏôÑÎ£å"
      ],
      "metadata": {
        "id": "ZVEzF7MgKnvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÌïôÏäµ/Í≤ÄÏ¶ù/ÌÖåÏä§Ìä∏Ïö© images, labels ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±. \n",
        "!mkdir /content/gdrive/MyDrive/YOLOv5/pig;\n",
        "!cd /content/gdrive/MyDrive/YOLOv5/pig; mkdir images; mkdir labels;\n",
        "!cd /content/gdrive/MyDrive/YOLOv5/pig/images; mkdir train; mkdir val; mkdir test\n",
        "!cd /content/gdrive/MyDrive/YOLOv5/pig/labels; mkdir train; mkdir val; mkdir test\n",
        "\n",
        "//Ïã§ÌñâÏôÑÎ£å"
      ],
      "metadata": {
        "id": "LhRZzZOwK7D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train Ïö© yolo Îç∞Ïù¥ÌÑ∞ ÏÑ∏Ìä∏ ÏÉùÏÑ±\n",
        "train_yolo_converter = COCO2YOLO(src_img_dir='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/images', json_file='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/train.json',\n",
        "                                 tgt_img_dir='/content/gdrive/MyDrive/YOLOv5/pig/images/train', tgt_anno_dir='/content/gdrive/MyDrive/YOLOv5/pig/labels/train')\n",
        "train_yolo_converter.coco2yolo()\n",
        "\n",
        "# val Ïö© yolo Îç∞Ïù¥ÌÑ∞ ÏÑ∏Ìä∏ ÏÉùÏÑ±. \n",
        "val_yolo_converter = COCO2YOLO(src_img_dir='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/images', json_file='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/val.json',\n",
        "                                 tgt_img_dir='/content/gdrive/MyDrive/YOLOv5/pig/images/val', tgt_anno_dir='/content/gdrive/MyDrive/YOLOv5/pig/labels/val')\n",
        "val_yolo_converter.coco2yolo()\n",
        "\n",
        "# test Ïö© yolo Îç∞Ïù¥ÌÑ∞ ÏÑ∏Ìä∏ ÏÉùÏÑ±. \n",
        "test_yolo_converter = COCO2YOLO(src_img_dir='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/images', json_file='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/test.json',\n",
        "                                 tgt_img_dir='/content/gdrive/MyDrive/YOLOv5/pig/images/test', tgt_anno_dir='/content/gdrive/MyDrive/YOLOv5/pig/labels/test')\n",
        "test_yolo_converter.coco2yolo()\n",
        "\n",
        "//Ïã§ÌñâÏôÑÎ£å"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n48IixgLRTt",
        "outputId": "de8b12d4-6e08-43a0-fca2-699c64734cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total images 1350\n",
            "total categories 1\n",
            "total labels 34575\n",
            "loading image info...\n",
            "loading done, total images 1350\n",
            "start converting...\n",
            "converting done, total labels 1350\n",
            "saving txt file...\n",
            "saving done\n",
            "total images 540\n",
            "total categories 1\n",
            "total labels 14941\n",
            "loading image info...\n",
            "loading done, total images 540\n",
            "start converting...\n",
            "converting done, total labels 540\n",
            "saving txt file...\n",
            "saving done\n",
            "total images 810\n",
            "total categories 1\n",
            "total labels 21635\n",
            "loading image info...\n",
            "loading done, total images 810\n",
            "start converting...\n",
            "converting done, total labels 810\n",
            "saving txt file...\n",
            "saving done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mv /content/pig/custom_data.yaml /content/gdrive/MyDrive/yolo/data/custom_data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHwL4maOjWqG",
        "outputId": "9dea8b0e-ab24-414b-e566-ef85ba1a6ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/pig/custom_data.yaml': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############Ïó¨Í∏∞ÏÑúÎ∂ÄÌÑ∞#################\n",
        "# Google Drive Ï†ëÍ∑ºÏùÑ ÏúÑÌïú Mount Ï†ÅÏö©. \n",
        "import os, sys \n",
        "from google.colab import drive \n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "s-KaC8jHj1NB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e0064f-59cd-4c71-e56a-7ed1087fbf8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWM3NCJ5IKdn",
        "outputId": "77d3c69a-e71c-47aa-baa3-9929e8486062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # soft linkÎ°ú Google Drive Directory Ïó∞Í≤∞. \n",
        "!ln -s /content/drive/My\\ Drive/ /mydrive\n",
        "\n",
        "!ls /mydrive\n",
        "# Google Drive Î∞ëÏóê Directory ÏÉùÏÑ±. Ïù¥ÎØ∏ ÏÉùÏÑ± ÎêòÏñ¥ ÏûàÏùÑ Ïãú Ïò§Î•ò Î∞úÏÉù. \n",
        "!mkdir \"/mydrive/ultra_workdir\""
      ],
      "metadata": {
        "id": "dEzKg_fUj1so",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6881147-757d-4a87-8a5e-56ab3e475a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/mydrive\n",
            "mkdir: cannot create directory ‚Äò/mydrive/ultra_workdir‚Äô: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "yaml.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RW52m3PJheHR",
        "outputId": "266835c0-ce0c-4a2e-f4b5-8b1bf050d743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !cd /content/gdrive/MyDrive/YOLOv5/yolov5; python train.py --img 640 --batch 8 --epochs 50 --data /content/gdrive/MyDrive/YOLOv5/custom_data.yaml --weights yolov5l.pt \\\n",
        "                                     --project=/content/gdrive/MyDrive/YOLOv5/ultra_workdir --name pig --exist-ok "
      ],
      "metadata": {
        "id": "DftQUi2Ij3hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ffb917-ce32-4a40-b8f8-b7d64757bfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=, data=/content/gdrive/MyDrive/YOLOv5/custom_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/gdrive/MyDrive/YOLOv5/ultra_workdir, name=pig, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "Command 'git fetch origin' timed out after 5 seconds\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirements \"ipython\" \"thop>=0.1.1\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (7.9.0)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1.6/1.6 MB 44.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from thop>=0.1.1) (1.13.1+cu116)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->thop>=0.1.1) (4.4.0)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.2 thop-0.1.1.post2209072238\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 2 packages updated per /content/gdrive/MyDrive/YOLOv5/yolov5/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 üöÄ v6.2-239-gf33718f Python-3.8.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/gdrive/MyDrive/YOLOv5/ultra_workdir', view at http://localhost:6006/\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 20 (delta 11), reused 15 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (20/20), done.\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 47.4MB/s]\n",
            "From https://github.com/ultralytics/yolov5\n",
            "   37d1e5e..cdd804d  master     -> origin/master\n",
            "   f5a2ff8..00070f3  exp13-soft -> origin/exp13-soft\n",
            " * [new branch]      v8_banner  -> origin/v8_banner\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model summary: 368 layers, 46138294 parameters, 46138294 gradients\n",
            "\n",
            "Transferred 607/613 items from yolov5l.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/gdrive/MyDrive/YOLOv5/pig/labels/train.cache' images and labels... 1350 found, 0 missing, 0 empty, 0 corrupt: 100% 1350/1350 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/gdrive/MyDrive/YOLOv5/pig/labels/val.cache' images and labels... 540 found, 0 missing, 0 empty, 0 corrupt: 100% 540/540 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.66 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
            "Plotting labels to /content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29      5.39G    0.08442     0.2469          0        242        640: 100% 169/169 [02:53<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [03:41<00:00,  6.52s/it]\n",
            "                   all        540      14522      0.659      0.712      0.733      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29      5.77G    0.06088     0.2174          0        247        640: 100% 169/169 [02:48<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.56it/s]\n",
            "                   all        540      14522      0.526      0.716      0.618      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/29      5.77G    0.05785     0.2126          0        229        640: 100% 169/169 [02:41<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:26<00:00,  1.30it/s]\n",
            "                   all        540      14522      0.717      0.724      0.787      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/29      5.77G    0.05276     0.2015          0        192        640: 100% 169/169 [02:42<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.862      0.863      0.928      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/29      5.77G    0.04634     0.2033          0        182        640: 100% 169/169 [02:47<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.948       0.92      0.972      0.606\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/29      5.77G     0.0447     0.1916          0        222        640: 100% 169/169 [02:46<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.66it/s]\n",
            "                   all        540      14522      0.952      0.907      0.969      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/29      5.77G    0.04279     0.1855          0        349        640: 100% 169/169 [02:45<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:19<00:00,  1.71it/s]\n",
            "                   all        540      14522      0.951      0.924      0.973      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/29      5.77G    0.04104     0.1877          0        298        640: 100% 169/169 [02:40<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.59it/s]\n",
            "                   all        540      14522      0.955      0.928      0.975      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/29      5.77G    0.04088     0.1853          0        244        640: 100% 169/169 [02:40<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.63it/s]\n",
            "                   all        540      14522      0.958      0.936      0.977      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/29      5.77G    0.03951     0.1776          0        285        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:19<00:00,  1.71it/s]\n",
            "                   all        540      14522      0.955      0.935      0.976      0.658\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/29      5.77G    0.03772     0.1785          0        419        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:19<00:00,  1.74it/s]\n",
            "                   all        540      14522      0.956      0.932      0.978      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/29      5.77G    0.03709      0.174          0        253        640: 100% 169/169 [02:40<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:25<00:00,  1.36it/s]\n",
            "                   all        540      14522      0.959      0.935      0.978      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/29      5.77G    0.03695     0.1732          0        425        640: 100% 169/169 [02:41<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:19<00:00,  1.73it/s]\n",
            "                   all        540      14522      0.957      0.938      0.978      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/29      5.77G     0.0359     0.1703          0        432        640: 100% 169/169 [02:43<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.61it/s]\n",
            "                   all        540      14522      0.959       0.94       0.98      0.689\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/29      5.77G     0.0356     0.1669          0        378        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.60it/s]\n",
            "                   all        540      14522      0.958      0.944       0.98      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/29      5.77G    0.03586     0.1671          0        269        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.61it/s]\n",
            "                   all        540      14522      0.962      0.939       0.98       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/29      5.77G     0.0354      0.169          0        316        640: 100% 169/169 [02:38<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.68it/s]\n",
            "                   all        540      14522       0.96      0.939      0.979      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/29      5.77G    0.03443     0.1639          0        469        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.961      0.942       0.98      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/29      5.77G    0.03426     0.1661          0        352        640: 100% 169/169 [02:43<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.962      0.943      0.981      0.702\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/29      5.77G    0.03348     0.1594          0        320        640: 100% 169/169 [02:42<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.962      0.939      0.979      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/29      5.77G    0.03318     0.1613          0        187        640: 100% 169/169 [02:38<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:24<00:00,  1.38it/s]\n",
            "                   all        540      14522      0.962      0.944      0.979      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/29      5.77G    0.03237     0.1554          0        213        640: 100% 169/169 [02:39<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.67it/s]\n",
            "                   all        540      14522      0.962      0.939      0.979      0.712\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/29      5.77G     0.0326     0.1568          0        331        640: 100% 169/169 [02:45<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.67it/s]\n",
            "                   all        540      14522      0.957      0.945      0.978      0.717\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/29      5.77G    0.03231     0.1565          0        267        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.65it/s]\n",
            "                   all        540      14522      0.961      0.942      0.979      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/29      5.77G    0.03134     0.1506          0        300        640: 100% 169/169 [02:37<00:00,  1.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:24<00:00,  1.38it/s]\n",
            "                   all        540      14522      0.961      0.944      0.978       0.72\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/29      5.77G    0.03155     0.1531          0        248        640: 100% 169/169 [02:38<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.68it/s]\n",
            "                   all        540      14522      0.964      0.943      0.978       0.72\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/29      5.77G    0.03111     0.1506          0        225        640: 100% 169/169 [02:40<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.65it/s]\n",
            "                   all        540      14522      0.962      0.945      0.978      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/29      5.77G    0.03101     0.1515          0        271        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.962      0.944      0.978      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/29      5.77G    0.03083     0.1497          0        318        640: 100% 169/169 [02:40<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.61it/s]\n",
            "                   all        540      14522      0.961      0.944      0.977      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/29      5.77G    0.03126      0.152          0        322        640: 100% 169/169 [02:45<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.68it/s]\n",
            "                   all        540      14522      0.964      0.944      0.978      0.727\n",
            "\n",
            "30 epochs completed in 1.621 hours.\n",
            "Optimizer stripped from /content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/weights/last.pt, 92.7MB\n",
            "Optimizer stripped from /content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/weights/best.pt, 92.7MB\n",
            "\n",
            "Validating /content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 267 layers, 46108278 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:25<00:00,  1.33it/s]\n",
            "                   all        540      14522      0.964      0.944      0.978      0.727\n",
            "Results saved to \u001b[1m/content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image ÌååÏùº inference \n",
        "!cd /content/gdrive/MyDrive/YOLOv5/yolov5;python detect.py --source /content/gdrive/MyDrive/YOLOv5/pig/images/test/ \\\n",
        "                            --weights /content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/weights/best_s.pt --conf 0.2 \\\n",
        "                            --project=/content/gdrive/MyDrive/data/ --name=run_image --exist-ok --line-thickness 3\n",
        "\n",
        "                            "
      ],
      "metadata": {
        "id": "KYEtF-JWkDuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fbba683-a0f5-4a3b-cbfd-63d5aa99686a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/weights/best_s.pt'], source=/content/gdrive/MyDrive/YOLOv5/pig/images/test/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.2, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/gdrive/MyDrive/data/, name=run_image, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 üöÄ v6.2-239-gf33718f Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 213 layers, 7020913 parameters, 0 gradients\n",
            "image 1/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/07d73716-fdb6-483b-a329-b5c202f0783c_vmj9_b4c3ad30-3e75-4d74-8adf-435dc261c11d_jpeg_jpg.rf.01c95271201dfeb948c54e8f02e1dd95.jpg: 640x640 (no detections), 11.6ms\n",
            "image 2/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/0aa24ad4-3fb7-4675-b255-0ae79cacf164_224g_47310b6b-eed6-4db7-bfff-737f91e0c57c_jpeg_jpg.rf.28e0b04b52878586a67aab8266ce5ed4.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 3/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/0f31446c-7087-4869-9447-3fc25b91e037_r62u_8252195b-3178-4010-a610-bd606a3d9a02_jpeg_jpg.rf.8d94b064b93e89f5aa70ed2c1d0a47ba.jpg: 640x640 2 scooters, 11.6ms\n",
            "image 4/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/16c789bb-d16b-473c-845c-2bfd660a7db3_jpeg_jpg.rf.647f09c3415e68aa521c1059dbe62b44.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 5/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/17be7382-1058-45b8-804d-d5ae1a3b34ad_jpeg_jpg.rf.24a4165f4c846988a8514ba29ea86fa1.jpg: 640x640 (no detections), 11.6ms\n",
            "image 6/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/1803e058-1564-420c-a2ab-97dcbd87f4e4_jpeg_jpg.rf.0ccfe4d1e335b2979f86486878dd52b1.jpg: 640x640 (no detections), 11.6ms\n",
            "image 7/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/190e51cd-1979-4aeb-b559-72de2f89aacc_jpeg_jpg.rf.0c02ccdebbbd84957192e4285e22831e.jpg: 640x640 (no detections), 11.6ms\n",
            "image 8/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/1c74fc50-b7f1-4c43-abf9-e14dbcf66ee9_jpeg_jpg.rf.f56ee5226ef722c04e3881be01176011.jpg: 640x640 (no detections), 11.6ms\n",
            "image 9/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/1df49386-763b-49d6-91a1-0e4df3705f8a_jpeg_jpg.rf.7bce7a54db955ba5199f41d044b15281.jpg: 640x640 (no detections), 11.6ms\n",
            "image 10/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/1fc28867-6a57-42d8-beb3-d4b54edb386a_jpeg_jpg.rf.3d2198b9eb52e5466640b20a6cebcebd.jpg: 640x640 2 scooters, 11.9ms\n",
            "image 11/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/23039292-3228-4004-811a-b26e3f91321e_jpeg_jpg.rf.7674b4b3b3604b901caf1b338f58cdf9.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 12/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/26ffecd6-dacb-4156-b248-cd3dbefc2712_jpeg_jpg.rf.0cfd3c540b9b625b0228479b6a432bde.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 13/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/27b5ef4b-bd1b-4b09-9728-eaa0b84683e1_x9l8_44aab85d-c3c3-4c49-ac17-d9d87f0f2313_jpeg_jpg.rf.aac57de4ba47a1ee1d44d91ebe721058.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 14/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/2c1301f1-1108-4c85-b2d0-ada5ebc7b837_jpeg_jpg.rf.369de02ce2353d7e07808f2f5a5d4f67.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 15/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/2fb8b8d6-ee0c-4a15-8c9a-c5401e556a39_jpeg_jpg.rf.2c332669a13bac6c4d6f5cb5a99b1c57.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 16/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/3696d4e7-2ff7-4953-970f-7922b8469321_jpeg_jpg.rf.3a2fc5c74c785dd631955aab26995b72.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 17/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/3ab8c949-f73d-4c9e-ae63-675645665149_jpeg_jpg.rf.f1be23507561fc25e95c225605842bcd.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 18/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/476f97b5-aaf6-4f32-a3c1-27dcb34df9ac_jpeg_jpg.rf.a329a975c853c355f536e8122acccd4d.jpg: 640x640 (no detections), 11.6ms\n",
            "image 19/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/4bc1585a-b82b-4ccd-91bc-4e7e518bf7cc_jpeg_jpg.rf.b11bad732273c6bb5350c7e08414061d.jpg: 640x640 (no detections), 11.6ms\n",
            "image 20/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/54d228d3-4dc5-452c-820f-b97a66ac0e72_jpeg_jpg.rf.d64e15435c9695145929885b040eadd6.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 21/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/5c481313-2872-4f53-b9b9-75d26dad9e9d_jpeg_jpg.rf.b257b1af34d39718d40d00275464a6f6.jpg: 640x640 1 whitelines, 11.7ms\n",
            "image 22/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/5dcbeb65-e640-446f-9bdc-41c2f66f000d_jpeg_jpg.rf.23d9e3f95cd3588201a7be890c658623.jpg: 640x640 1 rack_general, 11.6ms\n",
            "image 23/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/626c696a-5baf-4b20-98f3-3ace88ef4417_jpeg_jpg.rf.55d8da9c06aa6c1e60b81722ff932907.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 24/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/62d29bc1-91c0-4a38-ba13-cc8a198a4000_jpeg_jpg.rf.14f38211915cbf17956e5c67e4b51b72.jpg: 640x640 (no detections), 11.6ms\n",
            "image 25/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/638e2254-4c0e-4219-8a5c-84276a5c3a0e_dhuk_fe2d1ad5-b549-4bb1-8544-d8a63b77da54_jpeg_jpg.rf.a862119ffdb8246d3f2e2ec93d25629b.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 26/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6849812e-f244-44b2-b472-4a61ae9149d4_kr92_a660429d-2b67-4e97-b677-fff11c3b5e10_jpeg_jpg.rf.6105e6759173ae88b96e91ddc33f3582.jpg: 640x640 1 scooter, 11.7ms\n",
            "image 27/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6849812e-f244-44b2-b472-4a61ae9149d4_rs3g_f20ce9e1-e23a-4322-8337-089ecb82ff1d_jpeg_jpg.rf.664407992922d58267d0f49d5f5b47cc.jpg: 640x640 (no detections), 11.6ms\n",
            "image 28/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6bd116f9-70cb-4d12-9bbd-016c679e1e2a_3m4e_045d15d5-4c69-4921-af0b-6e9bb0071602_jpeg_jpg.rf.6dc2b7590c99899198d0d229b78d2262.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 29/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6c2670bd-4a16-468e-bc7f-9bbb0e6b954f_jpeg_jpg.rf.ca9a409b5bfbc592743093b8c74b1367.jpg: 640x640 (no detections), 11.6ms\n",
            "image 30/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6c7be9de-25b2-49ea-ab83-7d92f6294d64_jpeg_jpg.rf.20be0a788516f359b2fcd514dfde8267.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 31/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6dfffc20-43c6-4541-bd62-e61285e5997a_jpeg_jpg.rf.c7dc708a603a7d01165ef8d67223c7cd.jpg: 640x640 (no detections), 13.3ms\n",
            "image 32/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/840bdff9-db38-4234-ac09-7516b0e60d06_jpeg_jpg.rf.388d24ebac498113dddc4277c77d082d.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 33/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/8774e8c6-35f4-458b-b4ef-5e2fc9cfae1b_jpeg_jpg.rf.f6363685e02e9cfa22247a4c53a2e1d7.jpg: 640x640 (no detections), 11.6ms\n",
            "image 34/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/912fbff1-62d2-43fd-a1b9-8c5e270ded95_v2y5_3c85b008-906b-4d31-b514-2d2b78fa5201_jpeg_jpg.rf.0f03f3493a36c6a7b12ad7eab454dcfe.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 35/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/934bb87b-1d93-48cf-b8a9-904c6c9dc032_jpeg_jpg.rf.2900cc684508dddb5771ba620ac07156.jpg: 640x640 (no detections), 11.6ms\n",
            "image 36/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/934c469a-ac2d-4de5-8a3a-9bcc8f26e342_jpeg_jpg.rf.f9915a088d91c90c632c8f17d6159ecc.jpg: 640x640 (no detections), 11.6ms\n",
            "image 37/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/944b3736-d0c2-4f87-a928-2f306ea9fcd5_jpeg_jpg.rf.463bfdafa0addacfa2093dc33c4e3d25.jpg: 640x640 (no detections), 11.6ms\n",
            "image 38/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/950bc3c8-27ed-4963-beb5-048582834ca1_367s_46bda8da-036a-4efc-9033-284691330bf1_jpeg_jpg.rf.40b051ad46cd7e7ae46633d013b0581c.jpg: 640x640 (no detections), 11.6ms\n",
            "image 39/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/9624ea58-ec67-47ae-b7bf-679ccf7253dd_jpeg_jpg.rf.19dd4e366e12dfe38713669d3245f64d.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 40/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/98443d01-03ff-404b-9fd9-347b8da11920_jpeg_jpg.rf.eaedaf84e54f39fb20e979d403cc9253.jpg: 640x640 2 scooters, 11.6ms\n",
            "image 41/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/9b4ee6e7-0918-482c-8888-6d03f0f07b41_jpeg_jpg.rf.f1d0161e5293e83ebdd16243340946fd.jpg: 640x640 1 scooter, 11.7ms\n",
            "image 42/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/a4b483ad-1b47-411f-bed2-3e504efd07ae_jpeg_jpg.rf.9529a79c16ca117584c7008cc9b74cc7.jpg: 640x640 1 rack_general, 1 scooter, 11.6ms\n",
            "image 43/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/a5dada8b-b973-4563-9f13-37d5898e678c_jpeg_jpg.rf.0fe6e8c91f2dc021c4735a0cd92187af.jpg: 640x640 1 rack_general, 1 scooter, 11.6ms\n",
            "image 44/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/aa279db8-4928-4621-bd14-eae690f546b8_jpeg_jpg.rf.ba22ad01cc37a29d0a97957ec76749d5.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 45/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/afa81acd-d933-47f4-95e2-ad79675a1ce8_jpeg_jpg.rf.470eb847c1d53be1b53dfa2804b25097.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 46/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/affe4786-d446-4a55-aab8-7fd28c78e604_jpeg_jpg.rf.3feb7e7c0dc3ece3db2cea46b886a007.jpg: 640x640 (no detections), 11.6ms\n",
            "image 47/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/b0cb352a-34b8-4e8a-a843-3e7fc47e7325_653b_3541455a-7ac0-482a-b217-589674699249_jpeg_jpg.rf.fc11c8ffe0ffbb9f5f1e0d7566e9f6f6.jpg: 640x640 (no detections), 11.6ms\n",
            "image 48/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/b4fb01cb-e9a8-4eee-a293-5ccec72e4b07_8t4e_613b93c9-5b95-4a87-8f45-f22c54265fbe_jpeg_jpg.rf.3031bc57804b7d501c3c080b1dface5b.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 49/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/b79361fb-74f9-4e72-b639-0113dff15dcc_jpeg_jpg.rf.3b3063ba4f0fbd7cb0bff0f4b5ef6557.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 50/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/bb4a30e7-1f8b-4914-b1e6-2ece7adb5f9e_qe95_b8459418-031b-42a7-9bd8-b15afafe5f75_jpeg_jpg.rf.783b55aa90df252cb79c800b5e2616d8.jpg: 640x640 1 scooter, 11.7ms\n",
            "image 51/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/bbada4ad-c690-4b15-8fcd-900e4739537d_kzrh_e019854a-c9f4-498d-a1c4-2c5a7f8426a5_jpeg_jpg.rf.7b21c38a2559047cb04819c44bfe6c37.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 52/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/c316e4ac-98b5-408d-a2da-461fac93f455_jpeg_jpg.rf.b16ac0ae53955627924973dd71cedf5c.jpg: 640x640 (no detections), 11.7ms\n",
            "image 53/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/c4ca46ef-0b84-46ee-b233-bb064bdc032d_jpeg_jpg.rf.41527d5dcfd9182b2c9d825cc6594e87.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 54/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/c6eee201-1c44-4948-8ee7-bcecdaadeb25_gfc2_772906b9-e191-4bcb-9b3d-374fcfdc0535_jpeg_jpg.rf.8ca3ecf11f78ffb7910796821637b5d9.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 55/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/c8e64db5-8265-44c0-a4e4-0e4dcf1d895e_jpeg_jpg.rf.77eb8dfb66fd7c4030468b6b6922ae91.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 56/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/c9dca398-5080-4d78-9f40-f00e1cd058ca_jpeg_jpg.rf.56fcce05f9bc99651065ef6badaf370e.jpg: 640x640 1 rack_general, 1 scooter, 11.6ms\n",
            "image 57/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/d2d75591-d762-4d68-8a75-8b0b32e93472_jpeg_jpg.rf.1340f5f637954194e0125c2aebd4a96a.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 58/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/d34afeda-2b93-426c-8629-5909851a413a_n24k_8990277c-1712-4496-ac0f-66b629a11be1_jpeg_jpg.rf.eb537436a987bc7fc92e5a74798a1545.jpg: 640x640 (no detections), 11.6ms\n",
            "image 59/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/d98ee653-2e50-4dbe-b14e-54f04ee65f37_ptlf_bc7c995a-dd57-46e9-b33f-d291cb1521a3_jpeg_jpg.rf.2fe94c29fabaabc6d9f150e62e46ec21.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 60/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/db8a72f1-64db-485c-aadd-e15dea158a0c_gux9_3057ace7-9945-48be-8db8-7d170de55a70_jpeg_jpg.rf.c4b823c7aee083fc266b9eb537f4f1df.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 61/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/e7238c8f-e27d-4bb6-8a05-fc0791f2b8b9_hc42_cfa825c2-3f77-4c3b-b130-3e55e99dfae8_jpeg_jpg.rf.f1862d9bdd7811fb6245b64a1b242961.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 62/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/ea2fd9db-4eda-455a-8044-c04979d10498_jpeg_jpg.rf.68fd5ef7e291e704482ea1301760eab7.jpg: 640x640 1 scooter, 11.7ms\n",
            "image 63/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/eb8b3b2a-5ced-4bb7-9232-9191c17c8a86_nz5s_20e49a69-8a9c-4be5-8f48-41ccb6d2ad2e_jpeg_jpg.rf.e0e4e6610a2ad9f65c39ff53453ab272.jpg: 640x640 (no detections), 11.6ms\n",
            "image 64/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/efed0367-4a6e-4061-a717-c156aeb4dc39_jpeg_jpg.rf.87732c4b02e9fe245773a08860617df6.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 65/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/f88bb677-ec3b-43d8-bfdb-2b73b67e8a22_gdks_e5fab6e1-4073-493b-aecf-84ece573860c_jpeg_jpg.rf.f29867f4515b14b657e642b23ed0e8fe.jpg: 640x640 (no detections), 11.6ms\n",
            "image 66/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/fba5fd9f-4f58-451f-85c7-1af7e0cb1d4a_jpeg_jpg.rf.4703aa971bdedac4b78bcbb3c223bbe2.jpg: 640x640 (no detections), 11.6ms\n",
            "Speed: 0.7ms pre-process, 11.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/gdrive/MyDrive/data/run_image\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/yolov5; python test.py --weights /mydrive/ultra_workdir/bccd/weights/best.pt  --data /content/gdrive/MyDrive/yolo/data/custom_data.yaml \\\n",
        "                           --project /content/data/output --name=test_result --exist-ok --img 640 --iou 0.65\n",
        "\n",
        "                           //Ïã§ÌñâÏôÑÎ£å"
      ],
      "metadata": {
        "id": "INZfOcZRkSgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e5ee3a-b54d-49e4-9a4a-c8625148d770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'test.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    }
  ]
}