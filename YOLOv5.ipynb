{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gwan98/Project/blob/main/YOLOv5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYMuclM_N97m",
        "outputId": "41ab665f-025c-4840-8139-6845a32fe173"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolov5' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "!cd yolov5;pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/gdrive/MyDrive/data"
      ],
      "metadata": {
        "id": "sRymVdTCOCPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpaTWvsZODol",
        "outputId": "faa65e5b-ef84-4fd7-fa3d-bb735e2c277a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjbqcsOkhEU3",
        "outputId": "413096fa-aecf-4137-ad84-9bed247e26b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvR3Ay0KhUiX",
        "outputId": "a58923ee-dcd5-4638-87c7-5c548b3a3b88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import IntVar\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "\n",
        "\n",
        "def split_dataset(input_json, output_dir, val_ratio, test_ratio, random_seed):\n",
        "    random.seed(random_seed)\n",
        "\n",
        "    with open(input_json) as json_reader:\n",
        "        dataset = json.load(json_reader)\n",
        "\n",
        "    images = dataset['images']\n",
        "    annotations = dataset['annotations']\n",
        "    categories = dataset['categories']\n",
        "\n",
        "    # file_name에 prefix 디렉토리까지 포함 (CocoDataset 클래스를 사용하는 경우)\n",
        "    #for image in images:\n",
        "        #image['file_name'] = '{}/{}'.format(image['file_name'][0], image['file_name'])\n",
        "\n",
        "    image_ids = [x.get('id') for x in images]\n",
        "    image_ids.sort()\n",
        "    random.shuffle(image_ids)\n",
        "\n",
        "    num_val = int(len(image_ids) * val_ratio)\n",
        "    num_test = int(len(image_ids) * test_ratio)\n",
        "    num_train = int(len(image_ids)) - num_val - num_test\n",
        "\n",
        "    image_ids_val, image_ids_train , image_ids_test= set(image_ids[:num_val]), set(image_ids[num_val:num_train]), set(image_ids[num_train:])\n",
        "\n",
        "    train_images = [x for x in images if x.get('id') in image_ids_train]\n",
        "    val_images = [x for x in images if x.get('id') in image_ids_val]\n",
        "    test_images = [x for x in images if x.get('id') in image_ids_test]\n",
        "    train_annotations = [x for x in annotations if x.get('image_id') in image_ids_train]\n",
        "    val_annotations = [x for x in annotations if x.get('image_id') in image_ids_val]\n",
        "    test_annotations = [x for x in annotations if x.get('image_id') in image_ids_test]\n",
        "\n",
        "    train_data = {\n",
        "        'images': train_images,\n",
        "        'annotations': train_annotations,\n",
        "        'categories': categories,\n",
        "    }\n",
        "\n",
        "    val_data = {\n",
        "        'images': val_images,\n",
        "        'annotations': val_annotations,\n",
        "        'categories': categories,\n",
        "    }\n",
        "\n",
        "    test_data = {\n",
        "        'images': test_images,\n",
        "        'annotations': test_annotations,\n",
        "        'categories': categories,\n",
        "    }\n",
        "\n",
        "    output_seed_dir = os.path.join(output_dir, f'seed{random_seed}')\n",
        "    os.makedirs(output_seed_dir, exist_ok=True)\n",
        "    output_train_json = os.path.join(output_seed_dir, 'train.json')\n",
        "    output_val_json = os.path.join(output_seed_dir, 'val.json')\n",
        "    output_test_json = os.path.join(output_seed_dir, 'test.json')\n",
        "    output_train_csv = os.path.join(output_seed_dir, 'train.csv')\n",
        "    output_val_csv = os.path.join(output_seed_dir, 'val.csv')\n",
        "    output_test_csv = os.path.join(output_seed_dir, 'test.csv')\n",
        "\n",
        "    print(f'write {output_train_json}')\n",
        "    with open(output_train_json, 'w') as train_writer:\n",
        "        json.dump(train_data, train_writer)\n",
        "\n",
        "    print(f'write {output_val_json}')\n",
        "    with open(output_val_json, 'w') as val_writer:\n",
        "        json.dump(val_data, val_writer)\n",
        "\n",
        "    print(f'write {output_test_json}')\n",
        "    with open(output_test_json, 'w') as test_writer:\n",
        "        json.dump(test_data, test_writer)"
      ],
      "metadata": {
        "id": "jd7-Ta7GOHkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_dataset(input_json='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/annotation.json',\n",
        "              output_dir='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json',\n",
        "              val_ratio=0.2,\n",
        "              test_ratio=0.1,\n",
        "              random_seed=221112)\n",
        "\n",
        "//실행완료"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZfrKOtsJZtN",
        "outputId": "b9e68469-eec2-4f90-a3b3-955e5a436437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "write /content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/train.json\n",
            "write /content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/val.json\n",
            "write /content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/test.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/alexmihalyk23/COCO2YOLO.git\n",
        "//실행완료"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWVaySSkKDPS",
        "outputId": "75b036d1-3864-4c42-daa0-bd14f403e490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'COCO2YOLO'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (59/59), done.\u001b[K\n",
            "remote: Total 63 (delta 25), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "class COCO2YOLO:\n",
        "  # 소스 이미지 디렉토리와 Json annotation 파일, 타겟 이미지 디렉토리, 타겟 annotation 디렉토리를 생성자로 입력 받음. \n",
        "  def __init__(self, src_img_dir, json_file, tgt_img_dir, tgt_anno_dir):\n",
        "    self.json_file = json_file\n",
        "    self.src_img_dir = src_img_dir\n",
        "    self.tgt_img_dir = tgt_img_dir\n",
        "    self.tgt_anno_dir = tgt_anno_dir\n",
        "    # json 파일과 타겟 디렉토리가 존재하는지 확인하고, 디렉토리의 경우는 없으면 생성. \n",
        "    self._check_file_and_dir(json_file, tgt_img_dir, tgt_anno_dir)\n",
        "    # json 파일을 메모리로 로딩. \n",
        "    self.labels = json.load(open(json_file, 'r', encoding='utf-8'))\n",
        "    # category id와 이름을 매핑하지만, 실제 class id는 이를 적용하지 않고 별도 적용. \n",
        "    self.coco_id_name_map = self._categories()\n",
        "    self.coco_name_list = list(self.coco_id_name_map.values())\n",
        "    print(\"total images\", len(self.labels['images']))\n",
        "    print(\"total categories\", len(self.labels['categories']))\n",
        "    print(\"total labels\", len(self.labels['annotations']))\n",
        "  \n",
        "  # json 파일과 타겟 디렉토리가 존재하는지 확인하고, 디렉토리의 경우는 없으면 생성. \n",
        "  def _check_file_and_dir(self, file_path, tgt_img_dir, tgt_anno_dir):\n",
        "    if not os.path.exists(file_path):\n",
        "        raise ValueError(\"file not found\")\n",
        "    if not os.path.exists(tgt_img_dir):\n",
        "        os.makedirs(tgt_img_dir)\n",
        "    if not os.path.exists(tgt_anno_dir):\n",
        "        os.makedirs(tgt_anno_dir)\n",
        "\n",
        "  # category id와 이름을 매핑하지만, 추후에 class 명만 활용. \n",
        "  def _categories(self):\n",
        "    categories = {}\n",
        "    for cls in self.labels['categories']:\n",
        "        categories[cls['id']] = cls['name']\n",
        "    return categories\n",
        "  \n",
        "  # annotation에서 모든 image의 파일명(절대 경로 아님)과 width, height 정보 저장. \n",
        "  def _load_images_info(self):\n",
        "    images_info = {}\n",
        "    for image in self.labels['images']:\n",
        "        id = image['id']\n",
        "        file_name = image['file_name']\n",
        "        if file_name.find('\\\\') > -1:\n",
        "            file_name = file_name[file_name.index('\\\\')+1:]\n",
        "        w = image['width']\n",
        "        h = image['height']\n",
        "  \n",
        "        images_info[id] = (file_name, w, h)\n",
        "\n",
        "    return images_info\n",
        "\n",
        "  # ms-coco의 bbox annotation은 yolo format으로 변환. 좌상단 x, y좌표, width, height 기반을 정규화된 center x,y 와 width, height로 변환. \n",
        "  def _bbox_2_yolo(self, bbox, img_w, img_h):\n",
        "    # ms-coco는 좌상단 x, y좌표, width, height\n",
        "    x, y, w, h = bbox[0], bbox[1], bbox[2], bbox[3]\n",
        "    # center x좌표는 좌상단 x좌표에서 width의 절반을 더함. center y좌표는 좌상단 y좌표에서 height의 절반을 더함.  \n",
        "    centerx = bbox[0] + w / 2\n",
        "    centery = bbox[1] + h / 2\n",
        "    # centerx, centery, width, height를 이미지의 width/height로 정규화. \n",
        "    dw = 1 / img_w\n",
        "    dh = 1 / img_h\n",
        "    centerx *= dw\n",
        "    w *= dw\n",
        "    centery *= dh\n",
        "    h *= dh\n",
        "    return centerx, centery, w, h\n",
        "  \n",
        "  # image와 annotation 정보를 기반으로 image명과 yolo annotation 정보 가공. \n",
        "  # 개별 image당 하나의 annotation 정보를 가지도록 변환. \n",
        "  def _convert_anno(self, images_info):\n",
        "    anno_dict = dict()\n",
        "    for anno in self.labels['annotations']:\n",
        "      bbox = anno['bbox']\n",
        "      image_id = anno['image_id']\n",
        "      category_id = anno['category_id']\n",
        "\n",
        "      image_info = images_info.get(image_id)\n",
        "      image_name = image_info[0]\n",
        "      img_w = image_info[1]\n",
        "      img_h = image_info[2]\n",
        "      yolo_box = self._bbox_2_yolo(bbox, img_w, img_h)\n",
        "\n",
        "      anno_info = (image_name, category_id, yolo_box)\n",
        "      anno_infos = anno_dict.get(image_id)\n",
        "      if not anno_infos:\n",
        "        anno_dict[image_id] = [anno_info]\n",
        "      else:\n",
        "        anno_infos.append(anno_info)\n",
        "        anno_dict[image_id] = anno_infos\n",
        "    return anno_dict\n",
        "\n",
        "  # class 명을 파일로 저장하는 로직. 사용하지 않음. \n",
        "  def save_classes(self):\n",
        "    sorted_classes = list(map(lambda x: x['name'], sorted(self.labels['categories'], key=lambda x: x['id'])))\n",
        "    print('coco names', sorted_classes)\n",
        "    with open('coco.names', 'w', encoding='utf-8') as f:\n",
        "      for cls in sorted_classes:\n",
        "          f.write(cls + '\\n')\n",
        "    f.close()\n",
        "  # _convert_anno(images_info)로 만들어진 anno 정보를 개별 yolo anno txt 파일로 생성하는 로직. \n",
        "  # coco2yolo()에서 anno_dict = self._convert_anno(images_info)로 만들어진 anno_dict를 _save_txt()에 입력하여 파일 생성\n",
        "  def _save_txt(self, anno_dict):\n",
        "    # 개별 image별로 소스 image는 타겟이미지 디렉토리로 복사하고, 개별 annotation을 타겟 anno 디렉토리로 생성. \n",
        "    for k, v in anno_dict.items():\n",
        "      # 소스와 타겟 파일의 절대 경로 생성. \n",
        "      src_img_filename = os.path.join(self.src_img_dir, v[0][0])\n",
        "      tgt_anno_filename = os.path.join(self.tgt_anno_dir,v[0][0].split(\".\")[0] + \".txt\")\n",
        "      #print('source image filename:', src_img_filename, 'target anno filename:', tgt_anno_filename)\n",
        "      # 이미지 파일의 경우 타겟 디렉토리로 단순 복사. \n",
        "      shutil.copy(src_img_filename, self.tgt_img_dir)\n",
        "      # 타겟 annotation 출력 파일명으로 classid, bbox 좌표를 object 별로 생성. \n",
        "      with open(tgt_anno_filename, 'w', encoding='utf-8') as f:\n",
        "        #print(k, v)\n",
        "        # 여러개의 object 별로 classid와 bbox 좌표를 생성. \n",
        "        for obj in v:\n",
        "          cat_name = self.coco_id_name_map.get(obj[1])\n",
        "          # category_id는 class 명에 따라 0부터 순차적으로 부여. \n",
        "          category_id = self.coco_name_list.index(cat_name)\n",
        "          #print('cat_name:', cat_name, 'category_id:', category_id)\n",
        "          box = ['{:.6f}'.format(x) for x in obj[2]]\n",
        "          box = ' '.join(box)\n",
        "          line = str(category_id) + ' ' + box\n",
        "          f.write(line + '\\n')\n",
        "\n",
        "  # ms-coco를 yolo format으로 변환. \n",
        "  def coco2yolo(self):\n",
        "    print(\"loading image info...\")\n",
        "    images_info = self._load_images_info()\n",
        "    print(\"loading done, total images\", len(images_info))\n",
        "\n",
        "    print(\"start converting...\")\n",
        "    anno_dict = self._convert_anno(images_info)\n",
        "    print(\"converting done, total labels\", len(anno_dict))\n",
        "\n",
        "    print(\"saving txt file...\")\n",
        "    self._save_txt(anno_dict)\n",
        "    print(\"saving done\")\n",
        "\n",
        "    //실행완료"
      ],
      "metadata": {
        "id": "ZVEzF7MgKnvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습/검증/테스트용 images, labels 디렉토리 생성. \n",
        "!mkdir /content/gdrive/MyDrive/YOLOv5/pig;\n",
        "!cd /content/gdrive/MyDrive/YOLOv5/pig; mkdir images; mkdir labels;\n",
        "!cd /content/gdrive/MyDrive/YOLOv5/pig/images; mkdir train; mkdir val; mkdir test\n",
        "!cd /content/gdrive/MyDrive/YOLOv5/pig/labels; mkdir train; mkdir val; mkdir test\n",
        "\n",
        "//실행완료"
      ],
      "metadata": {
        "id": "LhRZzZOwK7D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train 용 yolo 데이터 세트 생성\n",
        "train_yolo_converter = COCO2YOLO(src_img_dir='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/images', json_file='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/train.json',\n",
        "                                 tgt_img_dir='/content/gdrive/MyDrive/YOLOv5/pig/images/train', tgt_anno_dir='/content/gdrive/MyDrive/YOLOv5/pig/labels/train')\n",
        "train_yolo_converter.coco2yolo()\n",
        "\n",
        "# val 용 yolo 데이터 세트 생성. \n",
        "val_yolo_converter = COCO2YOLO(src_img_dir='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/images', json_file='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/val.json',\n",
        "                                 tgt_img_dir='/content/gdrive/MyDrive/YOLOv5/pig/images/val', tgt_anno_dir='/content/gdrive/MyDrive/YOLOv5/pig/labels/val')\n",
        "val_yolo_converter.coco2yolo()\n",
        "\n",
        "# test 용 yolo 데이터 세트 생성. \n",
        "test_yolo_converter = COCO2YOLO(src_img_dir='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/images', json_file='/content/gdrive/MyDrive/YOLOv5/data/Train.vol1/json/seed221112/test.json',\n",
        "                                 tgt_img_dir='/content/gdrive/MyDrive/YOLOv5/pig/images/test', tgt_anno_dir='/content/gdrive/MyDrive/YOLOv5/pig/labels/test')\n",
        "test_yolo_converter.coco2yolo()\n",
        "\n",
        "//실행완료"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n48IixgLRTt",
        "outputId": "de8b12d4-6e08-43a0-fca2-699c64734cac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total images 1350\n",
            "total categories 1\n",
            "total labels 34575\n",
            "loading image info...\n",
            "loading done, total images 1350\n",
            "start converting...\n",
            "converting done, total labels 1350\n",
            "saving txt file...\n",
            "saving done\n",
            "total images 540\n",
            "total categories 1\n",
            "total labels 14941\n",
            "loading image info...\n",
            "loading done, total images 540\n",
            "start converting...\n",
            "converting done, total labels 540\n",
            "saving txt file...\n",
            "saving done\n",
            "total images 810\n",
            "total categories 1\n",
            "total labels 21635\n",
            "loading image info...\n",
            "loading done, total images 810\n",
            "start converting...\n",
            "converting done, total labels 810\n",
            "saving txt file...\n",
            "saving done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mv /content/pig/custom_data.yaml /content/gdrive/MyDrive/yolo/data/custom_data.yaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHwL4maOjWqG",
        "outputId": "9dea8b0e-ab24-414b-e566-ef85ba1a6ae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/pig/custom_data.yaml': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##############여기서부터#################\n",
        "# Google Drive 접근을 위한 Mount 적용. \n",
        "import os, sys \n",
        "from google.colab import drive \n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "s-KaC8jHj1NB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07e0064f-59cd-4c71-e56a-7ed1087fbf8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWM3NCJ5IKdn",
        "outputId": "77d3c69a-e71c-47aa-baa3-9929e8486062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # soft link로 Google Drive Directory 연결. \n",
        "!ln -s /content/drive/My\\ Drive/ /mydrive\n",
        "\n",
        "!ls /mydrive\n",
        "# Google Drive 밑에 Directory 생성. 이미 생성 되어 있을 시 오류 발생. \n",
        "!mkdir \"/mydrive/ultra_workdir\""
      ],
      "metadata": {
        "id": "dEzKg_fUj1so",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6881147-757d-4a87-8a5e-56ab3e475a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/mydrive\n",
            "mkdir: cannot create directory ‘/mydrive/ultra_workdir’: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "yaml.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RW52m3PJheHR",
        "outputId": "266835c0-ce0c-4a2e-f4b5-8b1bf050d743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !cd /content/gdrive/MyDrive/YOLOv5/yolov5; python train.py --img 640 --batch 8 --epochs 50 --data /content/gdrive/MyDrive/YOLOv5/custom_data.yaml --weights yolov5l.pt \\\n",
        "                                     --project=/content/gdrive/MyDrive/YOLOv5/ultra_workdir --name pig --exist-ok "
      ],
      "metadata": {
        "id": "DftQUi2Ij3hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ffb917-ce32-4a40-b8f8-b7d64757bfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l.pt, cfg=, data=/content/gdrive/MyDrive/YOLOv5/custom_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=/content/gdrive/MyDrive/YOLOv5/ultra_workdir, name=pig, exist_ok=True, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "Command 'git fetch origin' timed out after 5 seconds\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv5 requirements \"ipython\" \"thop>=0.1.1\" not found, attempting AutoUpdate...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (7.9.0)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython) (0.2.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 44.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython) (5.7.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython) (4.4.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from thop>=0.1.1) (1.13.1+cu116)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->thop>=0.1.1) (4.4.0)\n",
            "Installing collected packages: jedi, thop\n",
            "Successfully installed jedi-0.18.2 thop-0.1.1.post2209072238\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 2 packages updated per /content/gdrive/MyDrive/YOLOv5/yolov5/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "YOLOv5 🚀 v6.2-239-gf33718f Python-3.8.16 torch-1.13.1+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/gdrive/MyDrive/YOLOv5/ultra_workdir', view at http://localhost:6006/\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 20 (delta 11), reused 15 (delta 8), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (20/20), done.\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 47.4MB/s]\n",
            "From https://github.com/ultralytics/yolov5\n",
            "   37d1e5e..cdd804d  master     -> origin/master\n",
            "   f5a2ff8..00070f3  exp13-soft -> origin/exp13-soft\n",
            " * [new branch]      v8_banner  -> origin/v8_banner\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
            "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            "  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        \n",
            " 24      [17, 20, 23]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]\n",
            "Model summary: 368 layers, 46138294 parameters, 46138294 gradients\n",
            "\n",
            "Transferred 607/613 items from yolov5l.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 101 weight(decay=0.0), 104 weight(decay=0.0005), 104 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/gdrive/MyDrive/YOLOv5/pig/labels/train.cache' images and labels... 1350 found, 0 missing, 0 empty, 0 corrupt: 100% 1350/1350 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/gdrive/MyDrive/YOLOv5/pig/labels/val.cache' images and labels... 540 found, 0 missing, 0 empty, 0 corrupt: 100% 540/540 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.66 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to /content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29      5.39G    0.08442     0.2469          0        242        640: 100% 169/169 [02:53<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [03:41<00:00,  6.52s/it]\n",
            "                   all        540      14522      0.659      0.712      0.733      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29      5.77G    0.06088     0.2174          0        247        640: 100% 169/169 [02:48<00:00,  1.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.56it/s]\n",
            "                   all        540      14522      0.526      0.716      0.618      0.264\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/29      5.77G    0.05785     0.2126          0        229        640: 100% 169/169 [02:41<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:26<00:00,  1.30it/s]\n",
            "                   all        540      14522      0.717      0.724      0.787      0.388\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/29      5.77G    0.05276     0.2015          0        192        640: 100% 169/169 [02:42<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.862      0.863      0.928      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/29      5.77G    0.04634     0.2033          0        182        640: 100% 169/169 [02:47<00:00,  1.01it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.948       0.92      0.972      0.606\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/29      5.77G     0.0447     0.1916          0        222        640: 100% 169/169 [02:46<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.66it/s]\n",
            "                   all        540      14522      0.952      0.907      0.969      0.619\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/29      5.77G    0.04279     0.1855          0        349        640: 100% 169/169 [02:45<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:19<00:00,  1.71it/s]\n",
            "                   all        540      14522      0.951      0.924      0.973      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/29      5.77G    0.04104     0.1877          0        298        640: 100% 169/169 [02:40<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.59it/s]\n",
            "                   all        540      14522      0.955      0.928      0.975      0.635\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/29      5.77G    0.04088     0.1853          0        244        640: 100% 169/169 [02:40<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.63it/s]\n",
            "                   all        540      14522      0.958      0.936      0.977      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/29      5.77G    0.03951     0.1776          0        285        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:19<00:00,  1.71it/s]\n",
            "                   all        540      14522      0.955      0.935      0.976      0.658\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/29      5.77G    0.03772     0.1785          0        419        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:19<00:00,  1.74it/s]\n",
            "                   all        540      14522      0.956      0.932      0.978      0.662\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/29      5.77G    0.03709      0.174          0        253        640: 100% 169/169 [02:40<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:25<00:00,  1.36it/s]\n",
            "                   all        540      14522      0.959      0.935      0.978      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/29      5.77G    0.03695     0.1732          0        425        640: 100% 169/169 [02:41<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:19<00:00,  1.73it/s]\n",
            "                   all        540      14522      0.957      0.938      0.978      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/29      5.77G     0.0359     0.1703          0        432        640: 100% 169/169 [02:43<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.61it/s]\n",
            "                   all        540      14522      0.959       0.94       0.98      0.689\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/29      5.77G     0.0356     0.1669          0        378        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.60it/s]\n",
            "                   all        540      14522      0.958      0.944       0.98      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/29      5.77G    0.03586     0.1671          0        269        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.61it/s]\n",
            "                   all        540      14522      0.962      0.939       0.98       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/29      5.77G     0.0354      0.169          0        316        640: 100% 169/169 [02:38<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.68it/s]\n",
            "                   all        540      14522       0.96      0.939      0.979      0.698\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/29      5.77G    0.03443     0.1639          0        469        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.961      0.942       0.98      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/29      5.77G    0.03426     0.1661          0        352        640: 100% 169/169 [02:43<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.962      0.943      0.981      0.702\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/29      5.77G    0.03348     0.1594          0        320        640: 100% 169/169 [02:42<00:00,  1.04it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.962      0.939      0.979      0.703\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/29      5.77G    0.03318     0.1613          0        187        640: 100% 169/169 [02:38<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:24<00:00,  1.38it/s]\n",
            "                   all        540      14522      0.962      0.944      0.979      0.711\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/29      5.77G    0.03237     0.1554          0        213        640: 100% 169/169 [02:39<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.67it/s]\n",
            "                   all        540      14522      0.962      0.939      0.979      0.712\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/29      5.77G     0.0326     0.1568          0        331        640: 100% 169/169 [02:45<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.67it/s]\n",
            "                   all        540      14522      0.957      0.945      0.978      0.717\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/29      5.77G    0.03231     0.1565          0        267        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.65it/s]\n",
            "                   all        540      14522      0.961      0.942      0.979      0.714\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/29      5.77G    0.03134     0.1506          0        300        640: 100% 169/169 [02:37<00:00,  1.07it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:24<00:00,  1.38it/s]\n",
            "                   all        540      14522      0.961      0.944      0.978       0.72\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/29      5.77G    0.03155     0.1531          0        248        640: 100% 169/169 [02:38<00:00,  1.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.68it/s]\n",
            "                   all        540      14522      0.964      0.943      0.978       0.72\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/29      5.77G    0.03111     0.1506          0        225        640: 100% 169/169 [02:40<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.65it/s]\n",
            "                   all        540      14522      0.962      0.945      0.978      0.722\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/29      5.77G    0.03101     0.1515          0        271        640: 100% 169/169 [02:44<00:00,  1.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.62it/s]\n",
            "                   all        540      14522      0.962      0.944      0.978      0.725\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/29      5.77G    0.03083     0.1497          0        318        640: 100% 169/169 [02:40<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:21<00:00,  1.61it/s]\n",
            "                   all        540      14522      0.961      0.944      0.977      0.726\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/29      5.77G    0.03126      0.152          0        322        640: 100% 169/169 [02:45<00:00,  1.02it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:20<00:00,  1.68it/s]\n",
            "                   all        540      14522      0.964      0.944      0.978      0.727\n",
            "\n",
            "30 epochs completed in 1.621 hours.\n",
            "Optimizer stripped from /content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/weights/last.pt, 92.7MB\n",
            "Optimizer stripped from /content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/weights/best.pt, 92.7MB\n",
            "\n",
            "Validating /content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 267 layers, 46108278 parameters, 0 gradients\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:25<00:00,  1.33it/s]\n",
            "                   all        540      14522      0.964      0.944      0.978      0.727\n",
            "Results saved to \u001b[1m/content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# image 파일 inference \n",
        "!cd /content/gdrive/MyDrive/YOLOv5/yolov5;python detect.py --source /content/gdrive/MyDrive/YOLOv5/pig/images/test/ \\\n",
        "                            --weights /content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/weights/best_s.pt --conf 0.2 \\\n",
        "                            --project=/content/gdrive/MyDrive/data/ --name=run_image --exist-ok --line-thickness 3\n",
        "\n",
        "                            "
      ],
      "metadata": {
        "id": "KYEtF-JWkDuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fbba683-a0f5-4a3b-cbfd-63d5aa99686a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/gdrive/MyDrive/YOLOv5/ultra_workdir/pig/weights/best_s.pt'], source=/content/gdrive/MyDrive/YOLOv5/pig/images/test/, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.2, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/content/gdrive/MyDrive/data/, name=run_image, exist_ok=True, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v6.2-239-gf33718f Python-3.9.16 torch-2.0.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 213 layers, 7020913 parameters, 0 gradients\n",
            "image 1/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/07d73716-fdb6-483b-a329-b5c202f0783c_vmj9_b4c3ad30-3e75-4d74-8adf-435dc261c11d_jpeg_jpg.rf.01c95271201dfeb948c54e8f02e1dd95.jpg: 640x640 (no detections), 11.6ms\n",
            "image 2/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/0aa24ad4-3fb7-4675-b255-0ae79cacf164_224g_47310b6b-eed6-4db7-bfff-737f91e0c57c_jpeg_jpg.rf.28e0b04b52878586a67aab8266ce5ed4.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 3/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/0f31446c-7087-4869-9447-3fc25b91e037_r62u_8252195b-3178-4010-a610-bd606a3d9a02_jpeg_jpg.rf.8d94b064b93e89f5aa70ed2c1d0a47ba.jpg: 640x640 2 scooters, 11.6ms\n",
            "image 4/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/16c789bb-d16b-473c-845c-2bfd660a7db3_jpeg_jpg.rf.647f09c3415e68aa521c1059dbe62b44.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 5/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/17be7382-1058-45b8-804d-d5ae1a3b34ad_jpeg_jpg.rf.24a4165f4c846988a8514ba29ea86fa1.jpg: 640x640 (no detections), 11.6ms\n",
            "image 6/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/1803e058-1564-420c-a2ab-97dcbd87f4e4_jpeg_jpg.rf.0ccfe4d1e335b2979f86486878dd52b1.jpg: 640x640 (no detections), 11.6ms\n",
            "image 7/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/190e51cd-1979-4aeb-b559-72de2f89aacc_jpeg_jpg.rf.0c02ccdebbbd84957192e4285e22831e.jpg: 640x640 (no detections), 11.6ms\n",
            "image 8/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/1c74fc50-b7f1-4c43-abf9-e14dbcf66ee9_jpeg_jpg.rf.f56ee5226ef722c04e3881be01176011.jpg: 640x640 (no detections), 11.6ms\n",
            "image 9/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/1df49386-763b-49d6-91a1-0e4df3705f8a_jpeg_jpg.rf.7bce7a54db955ba5199f41d044b15281.jpg: 640x640 (no detections), 11.6ms\n",
            "image 10/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/1fc28867-6a57-42d8-beb3-d4b54edb386a_jpeg_jpg.rf.3d2198b9eb52e5466640b20a6cebcebd.jpg: 640x640 2 scooters, 11.9ms\n",
            "image 11/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/23039292-3228-4004-811a-b26e3f91321e_jpeg_jpg.rf.7674b4b3b3604b901caf1b338f58cdf9.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 12/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/26ffecd6-dacb-4156-b248-cd3dbefc2712_jpeg_jpg.rf.0cfd3c540b9b625b0228479b6a432bde.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 13/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/27b5ef4b-bd1b-4b09-9728-eaa0b84683e1_x9l8_44aab85d-c3c3-4c49-ac17-d9d87f0f2313_jpeg_jpg.rf.aac57de4ba47a1ee1d44d91ebe721058.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 14/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/2c1301f1-1108-4c85-b2d0-ada5ebc7b837_jpeg_jpg.rf.369de02ce2353d7e07808f2f5a5d4f67.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 15/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/2fb8b8d6-ee0c-4a15-8c9a-c5401e556a39_jpeg_jpg.rf.2c332669a13bac6c4d6f5cb5a99b1c57.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 16/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/3696d4e7-2ff7-4953-970f-7922b8469321_jpeg_jpg.rf.3a2fc5c74c785dd631955aab26995b72.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 17/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/3ab8c949-f73d-4c9e-ae63-675645665149_jpeg_jpg.rf.f1be23507561fc25e95c225605842bcd.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 18/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/476f97b5-aaf6-4f32-a3c1-27dcb34df9ac_jpeg_jpg.rf.a329a975c853c355f536e8122acccd4d.jpg: 640x640 (no detections), 11.6ms\n",
            "image 19/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/4bc1585a-b82b-4ccd-91bc-4e7e518bf7cc_jpeg_jpg.rf.b11bad732273c6bb5350c7e08414061d.jpg: 640x640 (no detections), 11.6ms\n",
            "image 20/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/54d228d3-4dc5-452c-820f-b97a66ac0e72_jpeg_jpg.rf.d64e15435c9695145929885b040eadd6.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 21/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/5c481313-2872-4f53-b9b9-75d26dad9e9d_jpeg_jpg.rf.b257b1af34d39718d40d00275464a6f6.jpg: 640x640 1 whitelines, 11.7ms\n",
            "image 22/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/5dcbeb65-e640-446f-9bdc-41c2f66f000d_jpeg_jpg.rf.23d9e3f95cd3588201a7be890c658623.jpg: 640x640 1 rack_general, 11.6ms\n",
            "image 23/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/626c696a-5baf-4b20-98f3-3ace88ef4417_jpeg_jpg.rf.55d8da9c06aa6c1e60b81722ff932907.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 24/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/62d29bc1-91c0-4a38-ba13-cc8a198a4000_jpeg_jpg.rf.14f38211915cbf17956e5c67e4b51b72.jpg: 640x640 (no detections), 11.6ms\n",
            "image 25/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/638e2254-4c0e-4219-8a5c-84276a5c3a0e_dhuk_fe2d1ad5-b549-4bb1-8544-d8a63b77da54_jpeg_jpg.rf.a862119ffdb8246d3f2e2ec93d25629b.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 26/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6849812e-f244-44b2-b472-4a61ae9149d4_kr92_a660429d-2b67-4e97-b677-fff11c3b5e10_jpeg_jpg.rf.6105e6759173ae88b96e91ddc33f3582.jpg: 640x640 1 scooter, 11.7ms\n",
            "image 27/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6849812e-f244-44b2-b472-4a61ae9149d4_rs3g_f20ce9e1-e23a-4322-8337-089ecb82ff1d_jpeg_jpg.rf.664407992922d58267d0f49d5f5b47cc.jpg: 640x640 (no detections), 11.6ms\n",
            "image 28/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6bd116f9-70cb-4d12-9bbd-016c679e1e2a_3m4e_045d15d5-4c69-4921-af0b-6e9bb0071602_jpeg_jpg.rf.6dc2b7590c99899198d0d229b78d2262.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 29/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6c2670bd-4a16-468e-bc7f-9bbb0e6b954f_jpeg_jpg.rf.ca9a409b5bfbc592743093b8c74b1367.jpg: 640x640 (no detections), 11.6ms\n",
            "image 30/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6c7be9de-25b2-49ea-ab83-7d92f6294d64_jpeg_jpg.rf.20be0a788516f359b2fcd514dfde8267.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 31/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/6dfffc20-43c6-4541-bd62-e61285e5997a_jpeg_jpg.rf.c7dc708a603a7d01165ef8d67223c7cd.jpg: 640x640 (no detections), 13.3ms\n",
            "image 32/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/840bdff9-db38-4234-ac09-7516b0e60d06_jpeg_jpg.rf.388d24ebac498113dddc4277c77d082d.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 33/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/8774e8c6-35f4-458b-b4ef-5e2fc9cfae1b_jpeg_jpg.rf.f6363685e02e9cfa22247a4c53a2e1d7.jpg: 640x640 (no detections), 11.6ms\n",
            "image 34/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/912fbff1-62d2-43fd-a1b9-8c5e270ded95_v2y5_3c85b008-906b-4d31-b514-2d2b78fa5201_jpeg_jpg.rf.0f03f3493a36c6a7b12ad7eab454dcfe.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 35/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/934bb87b-1d93-48cf-b8a9-904c6c9dc032_jpeg_jpg.rf.2900cc684508dddb5771ba620ac07156.jpg: 640x640 (no detections), 11.6ms\n",
            "image 36/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/934c469a-ac2d-4de5-8a3a-9bcc8f26e342_jpeg_jpg.rf.f9915a088d91c90c632c8f17d6159ecc.jpg: 640x640 (no detections), 11.6ms\n",
            "image 37/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/944b3736-d0c2-4f87-a928-2f306ea9fcd5_jpeg_jpg.rf.463bfdafa0addacfa2093dc33c4e3d25.jpg: 640x640 (no detections), 11.6ms\n",
            "image 38/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/950bc3c8-27ed-4963-beb5-048582834ca1_367s_46bda8da-036a-4efc-9033-284691330bf1_jpeg_jpg.rf.40b051ad46cd7e7ae46633d013b0581c.jpg: 640x640 (no detections), 11.6ms\n",
            "image 39/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/9624ea58-ec67-47ae-b7bf-679ccf7253dd_jpeg_jpg.rf.19dd4e366e12dfe38713669d3245f64d.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 40/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/98443d01-03ff-404b-9fd9-347b8da11920_jpeg_jpg.rf.eaedaf84e54f39fb20e979d403cc9253.jpg: 640x640 2 scooters, 11.6ms\n",
            "image 41/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/9b4ee6e7-0918-482c-8888-6d03f0f07b41_jpeg_jpg.rf.f1d0161e5293e83ebdd16243340946fd.jpg: 640x640 1 scooter, 11.7ms\n",
            "image 42/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/a4b483ad-1b47-411f-bed2-3e504efd07ae_jpeg_jpg.rf.9529a79c16ca117584c7008cc9b74cc7.jpg: 640x640 1 rack_general, 1 scooter, 11.6ms\n",
            "image 43/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/a5dada8b-b973-4563-9f13-37d5898e678c_jpeg_jpg.rf.0fe6e8c91f2dc021c4735a0cd92187af.jpg: 640x640 1 rack_general, 1 scooter, 11.6ms\n",
            "image 44/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/aa279db8-4928-4621-bd14-eae690f546b8_jpeg_jpg.rf.ba22ad01cc37a29d0a97957ec76749d5.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 45/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/afa81acd-d933-47f4-95e2-ad79675a1ce8_jpeg_jpg.rf.470eb847c1d53be1b53dfa2804b25097.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 46/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/affe4786-d446-4a55-aab8-7fd28c78e604_jpeg_jpg.rf.3feb7e7c0dc3ece3db2cea46b886a007.jpg: 640x640 (no detections), 11.6ms\n",
            "image 47/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/b0cb352a-34b8-4e8a-a843-3e7fc47e7325_653b_3541455a-7ac0-482a-b217-589674699249_jpeg_jpg.rf.fc11c8ffe0ffbb9f5f1e0d7566e9f6f6.jpg: 640x640 (no detections), 11.6ms\n",
            "image 48/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/b4fb01cb-e9a8-4eee-a293-5ccec72e4b07_8t4e_613b93c9-5b95-4a87-8f45-f22c54265fbe_jpeg_jpg.rf.3031bc57804b7d501c3c080b1dface5b.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 49/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/b79361fb-74f9-4e72-b639-0113dff15dcc_jpeg_jpg.rf.3b3063ba4f0fbd7cb0bff0f4b5ef6557.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 50/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/bb4a30e7-1f8b-4914-b1e6-2ece7adb5f9e_qe95_b8459418-031b-42a7-9bd8-b15afafe5f75_jpeg_jpg.rf.783b55aa90df252cb79c800b5e2616d8.jpg: 640x640 1 scooter, 11.7ms\n",
            "image 51/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/bbada4ad-c690-4b15-8fcd-900e4739537d_kzrh_e019854a-c9f4-498d-a1c4-2c5a7f8426a5_jpeg_jpg.rf.7b21c38a2559047cb04819c44bfe6c37.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 52/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/c316e4ac-98b5-408d-a2da-461fac93f455_jpeg_jpg.rf.b16ac0ae53955627924973dd71cedf5c.jpg: 640x640 (no detections), 11.7ms\n",
            "image 53/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/c4ca46ef-0b84-46ee-b233-bb064bdc032d_jpeg_jpg.rf.41527d5dcfd9182b2c9d825cc6594e87.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 54/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/c6eee201-1c44-4948-8ee7-bcecdaadeb25_gfc2_772906b9-e191-4bcb-9b3d-374fcfdc0535_jpeg_jpg.rf.8ca3ecf11f78ffb7910796821637b5d9.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 55/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/c8e64db5-8265-44c0-a4e4-0e4dcf1d895e_jpeg_jpg.rf.77eb8dfb66fd7c4030468b6b6922ae91.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 56/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/c9dca398-5080-4d78-9f40-f00e1cd058ca_jpeg_jpg.rf.56fcce05f9bc99651065ef6badaf370e.jpg: 640x640 1 rack_general, 1 scooter, 11.6ms\n",
            "image 57/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/d2d75591-d762-4d68-8a75-8b0b32e93472_jpeg_jpg.rf.1340f5f637954194e0125c2aebd4a96a.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 58/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/d34afeda-2b93-426c-8629-5909851a413a_n24k_8990277c-1712-4496-ac0f-66b629a11be1_jpeg_jpg.rf.eb537436a987bc7fc92e5a74798a1545.jpg: 640x640 (no detections), 11.6ms\n",
            "image 59/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/d98ee653-2e50-4dbe-b14e-54f04ee65f37_ptlf_bc7c995a-dd57-46e9-b33f-d291cb1521a3_jpeg_jpg.rf.2fe94c29fabaabc6d9f150e62e46ec21.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 60/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/db8a72f1-64db-485c-aadd-e15dea158a0c_gux9_3057ace7-9945-48be-8db8-7d170de55a70_jpeg_jpg.rf.c4b823c7aee083fc266b9eb537f4f1df.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 61/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/e7238c8f-e27d-4bb6-8a05-fc0791f2b8b9_hc42_cfa825c2-3f77-4c3b-b130-3e55e99dfae8_jpeg_jpg.rf.f1862d9bdd7811fb6245b64a1b242961.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 62/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/ea2fd9db-4eda-455a-8044-c04979d10498_jpeg_jpg.rf.68fd5ef7e291e704482ea1301760eab7.jpg: 640x640 1 scooter, 11.7ms\n",
            "image 63/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/eb8b3b2a-5ced-4bb7-9232-9191c17c8a86_nz5s_20e49a69-8a9c-4be5-8f48-41ccb6d2ad2e_jpeg_jpg.rf.e0e4e6610a2ad9f65c39ff53453ab272.jpg: 640x640 (no detections), 11.6ms\n",
            "image 64/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/efed0367-4a6e-4061-a717-c156aeb4dc39_jpeg_jpg.rf.87732c4b02e9fe245773a08860617df6.jpg: 640x640 1 scooter, 11.6ms\n",
            "image 65/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/f88bb677-ec3b-43d8-bfdb-2b73b67e8a22_gdks_e5fab6e1-4073-493b-aecf-84ece573860c_jpeg_jpg.rf.f29867f4515b14b657e642b23ed0e8fe.jpg: 640x640 (no detections), 11.6ms\n",
            "image 66/66 /content/gdrive/MyDrive/YOLOv5/pig/images/test/fba5fd9f-4f58-451f-85c7-1af7e0cb1d4a_jpeg_jpg.rf.4703aa971bdedac4b78bcbb3c223bbe2.jpg: 640x640 (no detections), 11.6ms\n",
            "Speed: 0.7ms pre-process, 11.6ms inference, 0.9ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/gdrive/MyDrive/data/run_image\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/yolov5; python test.py --weights /mydrive/ultra_workdir/bccd/weights/best.pt  --data /content/gdrive/MyDrive/yolo/data/custom_data.yaml \\\n",
        "                           --project /content/data/output --name=test_result --exist-ok --img 640 --iou 0.65\n",
        "\n",
        "                           //실행완료"
      ],
      "metadata": {
        "id": "INZfOcZRkSgm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e5ee3a-b54d-49e4-9a4a-c8625148d770"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'test.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    }
  ]
}